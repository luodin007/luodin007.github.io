---
layout: post
title:  "对海量HTTP响应报文进行聚类分析——相似性算法调研"
date:   2015-05-02 21:10:12
categories: 海量数据
comments: true
---

最近有个任务，就是对海量（亿级）HTTP响应报文进行分析，提取出有效的信息并加以识别。通过人肉当然是解决不了的，只有硬着头皮去研究一些数据挖掘的算法，然后根据自己需求胡乱拼装起来。只了解到皮毛，本文也是东拼西凑、集各家的内容，所以可能有错用误用的地方，欢迎指出。因为参考文章过多，参考列表可能会有遗漏，请多包涵。  


# 对问题的分析
现在手中有[大约72G HTTP响应报文数据](https://scans.io/study/sonar.http)  ，我从中提取出5w条作为样本分析，每一条报文被保存在一个以内容MD5作为文件名的文本文件中，HTTP报文包括HTTP响应头（header）和响应包体（html）两部分。   
我们如果要对响应报文进行分析，首先要将相似的报文进行聚类，之后对聚类结果进行自动或半自动的分析处理，得到特征指纹以便更大范围的识别。所以我们需要对大量数据相似性归类的算法和对已有数据训练提取有效信息的算法。  

# 相似性算法调研  
对我们来说header中的日期和html中的绝大多数内容都是没有分析价值的，但是他们会对我们的分析造成影响，用行话说这是噪音。如何有效的去除噪音，如果能将我们认为相似的报文归为一类是我需要第一时间解决的，当然还要适用于大规模数据分析。而算法调研就是基于这三点展开的。  

###  **MD5**  
这是最最最单纯的比较两个文件或信息是否相同，MD5的设计的目的是为了让整个分布尽可能地均匀，分布到两条不同信息的hash很难发生碰撞，内容哪怕只有轻微变化，hash就会发生很大地变化。而我们需要相似的内容的hashcode的相似程度要尽可能高，不同的相似程度尽可能低，所以传统的Hash是无法满足的，这里提它只是卖萌。。。  

### **距离编辑（Levenshtein Distance / Edit Distance）  **
编辑距离是指两个字符串之间，由字符串A通过编辑操作成为成为字符串B，编辑操作包括插入一个字符、删除一个字符、替换一个字符。操作的过程的次数表示两个字符串的差异，如果编辑次数越少，我们认为他们俩的相似程度越高。  

	例如  
	将kitten转换sitting：    
	sitten （k→s）  
	sittin （e→i）  
	sitting （→g）  

俄罗斯科学家Vladimir Levenshtein在1965年提出这一概念。

* **优点**：
1. 发扬了毛子简单粗暴的性格，单纯而又直接。 

* **缺点**：
1. 字符串越长匹配的时间越长，对于大规模的长字符串比较并不适用。  

### **余弦相似性算法（Cosine Similiarity）  **
余弦相似性是比较两个文件是否相似的常用办法，简单来说就是测量两个文件的词频向量内积的**空间夹角**的余弦值来度量他们之间的相似性，如果夹角为0度，意味着方向相同、线段重合；如果夹角为90度，意味着形成直角，方向完全不相似；如果夹角为180度，意味着方向正好相反。因此，我们可以通过夹角的大小，来判断向量的相似程度。夹角越小，就代表越相似。  
对于一个二维空间来说，如果要计算两个向量的夹角，根据余弦定理：  
![二维空间中计算余弦](http://7xiprm.com1.z0.glb.clouddn.com/.1430573919532.png)
推广到n维向量空间：
![N维空间计算余弦](http://7xiprm.com1.z0.glb.clouddn.com/.1430574619010.png)
对词频向量求夹角后只需要比较夹角即可得到两文件的相似程度。
**欧氏距离**与余弦距离类似，只不过欧氏距离衡量的是空间各点的绝对距离，跟各个点所在的位置坐标直接相关；而余弦距离衡量的是空间向量的夹角，更加体现在方向上的差异。这里当做一类算法进行说明。
* **优点**：
	1. 容易实现。
* **缺点**：
	1.  相似度比较必须两两相比，不适用于大量文件比较。
	2.  如果对全文计算特征向量导致向量维度很高，计算速度比较慢；如果部分计算误差较大。

###  **Simhash**
simhash是由 Charikar 在2002年提出来的，主要是Google用于网页去重，这是一种基于LSH的标签算法。算法的主要思想是降维，将高维的特征向量映射成一个f-bit的指纹(fingerprint)，通过比较两篇文章的f-bit指纹的Hamming Distance来确定文章是否重复或者高度近似。由于每篇文章我们都可以事先计算好Hamming Distance来保存，到时候直接通过Hamming Distance来计算，只用计算一次标签，虽然可能需要两两匹配，但是这也节约了很多的计算量。所以速度非常快适合大数据计算。

假设我有三个字符串，简单起见我们使用英文字符串，例子也是别人的例子  
* the cat sat on the mat  
* the cat sat on a mat  
* we all scream for ice cream  

	####算法流程如下：
1. 选择simhash的长度位数（二进制），请综合考虑存储成本以及数据集的大小，比如说64位  
2. 将simhash的各位初始化为0，得到64位的全0一维矩阵   
3. 提取原始文本中的特征，一般采用各种分词的方式。比如对于"the cat sat on the mat"，使用python常用的字符串分割split得到：['the', 'cat', 'sat', 'on', 'the', 'mat']  
4. 对分词后的word进行加权，这里方便起见，权重都为1.  
5. 计算各个word的hash值，这一步可以自由发挥，测试找到最快效果最好的算法。假设结果为[1001000]  
6. 对每个word的hash值的每一位乘以权重，如果是当前位为1则为结果为w，如果为0则结果为-w。因为我们权重为1，所以结果为[1,-1,-1,1,-1,-1,-1]  
7.  将所有word经过权重处理后的hash值按位相加，假设结果为[13,108,-22,-5,23,55]  
8.  对上一步的结果进行处理，如果该位大于等于0则记为1，如果小于0则记为0.  
9.  这样我们就得到了最终文本simhash值，结果为[1,1,0,0,1,1]  
![simhash算法流程图](http://7xiprm.com1.z0.glb.clouddn.com/.1430579971731.png)

	###匹配流程：  
1. 得到两个文本的simhash值，假设为hash1（110011）和hash2（010001）  
2. 我们通过求汉明距离（Hamming distance）得到两hash 值的相似程度  
	hash1 ：  **1**100**1**1  
	hash2  ： **0**101**0**1  
	两个hash之间有2位不同，即汉明距离为2  
3. 通过测试得到汉明距离阈值，如果小于阈值则说明两文本为相似  

* **优点**：  
1. 只需要计算一次hash值，之后可以直接使用，节约了计算量。
2. 可以配合TF-IDF算法或人工添加权重，提高算法的匹配精度。

* **缺点**：  
1. 因为短文本信息量不足，所以效果并不是很好。  
2. 需要两两匹配才能确定是否相似  
3. 算法是Google用来网页去重的，可能不适用于我们“认为相似的报文”归类这一问题。 

###  **其他  **
其实相似归类算法还有很多，因为时间紧急所以就没做研究。 

#最终选择  
最终选择了simhash。Google信仰加成是一方面，之前做过图像相似使用的类似的感知哈希算法与之很类似，所以感觉很亲切。  
虽然它有很多缺点，但是先run起来，以后有很多方案进行解决。这些都不是论文能够帮得了我的。   
其实后来的事实证明，通过对算法进行修改和调试，是可以用于我这个问题的。  


###Reference：
[1] [余弦相似性 - 维基百科](http://zh.wikipedia.org/wiki/%E4%BD%99%E5%BC%A6%E7%9B%B8%E4%BC%BC%E6%80%A7)  
[2] [海量数据相似度计算之simhash和海明距离 | 严澜(lanceyan)的博客](http://www.lanceyan.com/tech/arch/simhash_hamming_distance_similarity.html)  
[3] [海量数据相似度计算之simhash短文本查找 | 严澜(lanceyan)的博客](http://www.lanceyan.com/tech/arch/simhash_hamming_distance_similarity2-html.html)  
[4] [局部敏感哈希(Locality-Sensitive Hashing, LSH)方法介绍 - CVPR|OpenCV|图像检索|视频检索 - 博客频道 - CSDN.NET](http://blog.csdn.net/icvpr/article/details/12342159)  
[5] [TF-IDF与余弦相似性的应用（二）：找出相似文章 - 阮一峰的网络日志](http://www.ruanyifeng.com/blog/2013/03/cosine_similarity.html)  
[6] [如何计算两个文档的相似度（一） | 我爱自然语言处理](http://www.52nlp.cn/%E5%A6%82%E4%BD%95%E8%AE%A1%E7%AE%97%E4%B8%A4%E4%B8%AA%E6%96%87%E6%A1%A3%E7%9A%84%E7%9B%B8%E4%BC%BC%E5%BA%A6%E4%B8%80)  

